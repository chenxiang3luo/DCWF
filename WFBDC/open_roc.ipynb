{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from util.model import DF\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './pre_trained_model/finish_model_BDC.pt'\n",
    "checkpoint = torch.load(model_path)\n",
    "feature_model = DF()\n",
    "feature_model.cuda()\n",
    "feature_model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_set_AWF_open(features_model,dataset,shot,size,class_num):\n",
    "    n_query = 70\n",
    "    clf = torch.nn.Sequential(torch.nn.Linear(32896,class_num)).cuda()\n",
    "    clf.load_state_dict(torch.load(f'./pre_trained_model/open_model_{dataset}_{shot}.pt'))\n",
    "    train_name = f'/root/datasets/FSCIL/{dataset}.npz'\n",
    "    train_dataset = np.load(train_name,allow_pickle=True)\n",
    "    train_data = train_dataset['data']\n",
    "    train_labels = train_dataset['labels']\n",
    "    if( shot == 20 and dataset == 'KNN'):\n",
    "        X_test = train_data\n",
    "        y_test = train_labels\n",
    "    else:\n",
    "        X_train,X_test, y_train, y_test =train_test_split(train_data,train_labels,test_size=(shot+n_query)*class_num, random_state=42,shuffle=True,stratify=train_labels)\n",
    "    y_test = np.array([str(lab) for lab in y_test])\n",
    "    unique = np.unique(y_test)\n",
    "    unique = unique[np.random.permutation(unique.shape[0])]\n",
    "    labels = []\n",
    "    proba = []\n",
    "    for cla in unique:\n",
    "        inds_train = np.argwhere(y_test==cla)\n",
    "\n",
    "        samples_train = inds_train.reshape(-1)\n",
    "        \n",
    "        query = np.array(X_test[samples_train][shot:])\n",
    "        query = query.reshape(query.shape[0],1,query.shape[1])\n",
    "\n",
    "        query = torch.tensor(query,dtype=torch.float32).cuda()\n",
    "        features_model.eval()\n",
    "        clf.eval()\n",
    "        with torch.no_grad():\n",
    "            proba.extend(softmax(clf(features_model(query)).cpu().numpy()))\n",
    "            labels.extend([1 for i in range(n_query)])\n",
    "    print(len(labels))\n",
    "    train_name = f'/root/datasets/FSCIL/AWF_{size}.npz'\n",
    "    train_dataset = np.load(train_name,allow_pickle=True)\n",
    "    train_data = train_dataset['data']\n",
    "    for i in range(0,size,200):\n",
    "        query = np.array(train_data[i:i+200])\n",
    "        query = query.reshape(query.shape[0],1,query.shape[1])\n",
    "        query = torch.tensor(query,dtype=torch.float32).cuda()\n",
    "        features_model.eval()\n",
    "        clf.eval()\n",
    "        with torch.no_grad():\n",
    "            proba.extend(softmax(clf(features_model(query)).cpu().numpy()))\n",
    "            labels.extend([0 for i in range(200)])\n",
    "    print(len(labels))\n",
    "    return proba, labels\n",
    "\n",
    "def cross_entropy(predictions, targets):\n",
    "    epsilon = 1e-12  # 添加一个小的常数，避免log(0)的情况\n",
    "\n",
    "    predictions = np.clip(predictions, epsilon, 1.0 - epsilon)  # 限制预测值的范围\n",
    "    ce = -np.sum(targets * np.log(predictions), axis=1)  # 计算交叉熵\n",
    "\n",
    "    return ce\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # 减去最大值，以避免溢出\n",
    "    return e_x / np.sum(e_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6650\n",
      "15650\n",
      "0.7722360735171261\n",
      "6650\n",
      "15650\n",
      "0.8483282289055973\n",
      "6650\n",
      "15650\n",
      "0.8726591812865497\n",
      "6650\n",
      "15650\n",
      "0.8942187635756057\n",
      "6650\n",
      "15650\n",
      "0.9042164745196326\n"
     ]
    }
   ],
   "source": [
    "for shot in [1,5,10,15,20]:\n",
    "    size = 9000\n",
    "    class_num = 95\n",
    "    prob,lab = create_test_set_AWF_open(feature_model,'DF95',shot,size,class_num)\n",
    "    if(size == 400000):\n",
    "        for i in range(11):\n",
    "            lab.pop()\n",
    "        tol = 70*class_num+size-11\n",
    "    else:\n",
    "        tol = 70*class_num+size\n",
    "    prob = np.array(prob)\n",
    "    ll = np.ones([tol, class_num])\n",
    "    va = cross_entropy(prob,ll)\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import precision_recall_curve,roc_auc_score\n",
    "    precision, recall, thresholds = precision_recall_curve(lab,va)\n",
    "    # plt.plot(recall, precision)\n",
    "    # plt.xlabel('Recall')\n",
    "    # plt.ylabel('Precision')\n",
    "    # plt.title('Precision-Recall Curve')\n",
    "    # plt.show()\n",
    "    print(roc_auc_score(lab,va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "57000\n",
      "0.8287020885714285\n",
      "7000\n",
      "107000\n",
      "0.82935456\n",
      "7000\n",
      "207000\n",
      "0.8293642214285714\n",
      "7000\n",
      "407000\n",
      "0.8293004243330977\n"
     ]
    }
   ],
   "source": [
    "for size in [50000,100000,200000,400000]:\n",
    "    shot=10\n",
    "    class_num = 100\n",
    "    prob,lab = create_test_set_AWF_open(feature_model,'tor_100w_2500tr',shot,size,class_num)\n",
    "    if(size == 400000):\n",
    "        for i in range(11):\n",
    "            lab.pop()\n",
    "        tol = 70*class_num+size-11\n",
    "    else:\n",
    "        tol = 70*class_num+size\n",
    "    prob = np.array(prob)\n",
    "    ll = np.ones([tol, class_num])\n",
    "    va = cross_entropy(prob,ll)\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import precision_recall_curve,roc_auc_score\n",
    "    precision, recall, thresholds = precision_recall_curve(lab,va)\n",
    "    # plt.plot(recall, precision)\n",
    "    # plt.xlabel('Recall')\n",
    "    # plt.ylabel('Precision')\n",
    "    # plt.title('Precision-Recall Curve')\n",
    "    # plt.show()\n",
    "    print(roc_auc_score(lab,va))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
